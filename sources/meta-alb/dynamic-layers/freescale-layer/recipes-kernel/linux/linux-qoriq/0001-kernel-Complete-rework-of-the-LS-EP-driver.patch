From 7dd3f96a13b1aacee54dae779f4fdb280280561f Mon Sep 17 00:00:00 2001
From: r39252 <Heinz.Wrobel@freescale.com>
Date: Mon, 24 Apr 2017 15:20:51 +0200
Subject: [PATCH 1/2] kernel: Complete rework of the LS EP driver

The driver was very much broken. It didn't deal with link changes.
SR_IOV support was definitely broken. The debugfs driver did not
properly free some data and caused kernel faulty.
Registers were not matching the implementation.
SoCs without EP support were listed as supported
---
 drivers/pci/host/pci-layerscape-ep-debugfs.c | 123 ++++---
 drivers/pci/host/pci-layerscape-ep.c         | 457 +++++++++++++++++++++++----
 drivers/pci/host/pci-layerscape-ep.h         |  85 ++++-
 3 files changed, 531 insertions(+), 134 deletions(-)

diff --git a/drivers/pci/host/pci-layerscape-ep-debugfs.c b/drivers/pci/host/pci-layerscape-ep-debugfs.c
index 5f4870bac997..1e58f59035c4 100644
--- a/drivers/pci/host/pci-layerscape-ep-debugfs.c
+++ b/drivers/pci/host/pci-layerscape-ep-debugfs.c
@@ -33,7 +33,7 @@
 #define PCIE_BAR0_SIZE		(4 * 1024) /* 4K */
 #define PCIE_BAR1_SIZE		(8 * 1024) /* 8K for MSIX */
 #define PCIE_BAR2_SIZE		(4 * 1024) /* 4K */
-#define PCIE_BAR4_SIZE		(1 * 1024 * 1024) /* 1M */
+#define PCIE_BAR4_SIZE		(16 * 1024 * 1024) /* 16M */
 #define PCIE_MSI_OB_SIZE	(4 * 1024) /* 4K */
 
 #define PCIE_MSI_MSG_ADDR_OFF	0x54
@@ -279,6 +279,7 @@ int ls_pcie_ep_test_thread(void *arg)
 
 static int ls_pcie_ep_free_test(struct ls_ep_dev *ep)
 {
+	struct ls_pcie *pcie = ep->pcie;
 	struct ls_ep_test *test = ep->driver_data;
 
 	if (!test)
@@ -292,8 +293,8 @@ static int ls_pcie_ep_free_test(struct ls_ep_dev *ep)
 	}
 
 	if (test->buf)
-		free_pages((unsigned long)test->buf,
-			   get_order(PCIE_BAR4_SIZE));
+		dma_free_coherent(pcie->dev, get_order(ep->bar4_size),
+				  test->buf, test->buf_addr);
 
 	if (test->cfg)
 		free_pages((unsigned long)test->cfg,
@@ -328,7 +329,9 @@ static int ls_pcie_ep_init_test(struct ls_ep_dev *ep, u64 bus_addr)
 	spin_lock_init(&test->lock);
 	test->status = TEST_IDLE;
 
-	test->buf = dma_alloc_coherent(pcie->dev, get_order(PCIE_BAR4_SIZE),
+	if(!ep->bar4_size)
+		ep->bar4_size = PCIE_BAR4_SIZE;
+	test->buf = dma_alloc_coherent(pcie->dev, get_order(ep->bar4_size),
 					&test->buf_addr,
 					GFP_KERNEL);
 	if (!test->buf) {
@@ -340,14 +343,14 @@ static int ls_pcie_ep_init_test(struct ls_ep_dev *ep, u64 bus_addr)
 	test->cfg = (void *)__get_free_pages(GFP_KERNEL | __GFP_ZERO,
 					     get_order(PCIE_BAR2_SIZE));
 	if (!test->cfg) {
-		dev_info(&ep->dev, "failed to get mem for bar4\n");
+		dev_info(&ep->dev, "failed to get mem for bar2\n");
 		err = -ENOMEM;
 		goto _err;
 	}
 	test->cfg_addr = virt_to_phys(test->cfg);
 
 	test->out_addr = pcie->out_base;
-	test->out = ioremap(test->out_addr, PCIE_BAR4_SIZE);
+	test->out = ioremap(test->out_addr, ep->bar4_size);
 	if (!test->out) {
 		dev_info(&ep->dev, "failed to map out\n");
 		err = -ENOMEM;
@@ -356,31 +359,39 @@ static int ls_pcie_ep_init_test(struct ls_ep_dev *ep, u64 bus_addr)
 
 	test->bus_addr = bus_addr;
 
-	test->msi_addr = test->out_addr + PCIE_BAR4_SIZE;
+	test->msi_addr = test->out_addr + ep->bar4_size;
 	test->msi = ioremap(test->msi_addr, PCIE_MSI_OB_SIZE);
 	if (!test->msi)
 		dev_info(&ep->dev, "failed to map MSI outbound region\n");
 
-	test->msi_msg_addr = ioread32(pcie->dbi + PCIE_MSI_MSG_ADDR_OFF) |
-		(((u64)ioread32(pcie->dbi + PCIE_MSI_MSG_ADDR_OFF + 4)) << 32);
-	test->msi_msg_data = ioread16(pcie->dbi + PCIE_MSI_MSG_DATA_OFF);
-
-	ls_pcie_ep_dev_cfg_enable(ep);
+	test->msi_msg_addr = ls_pcie_dbi_ioread32(ep, PCIE_MSI_MSG_ADDR_OFF) |
+		(((u64)ls_pcie_dbi_ioread32(ep, PCIE_MSI_MSG_ADDR_OFF + 4)) << 32);
+	test->msi_msg_data = ls_pcie_dbi_ioread16(ep, PCIE_MSI_MSG_DATA_OFF);
 
 	/* outbound iATU for memory */
-	ls_pcie_iatu_outbound_set(pcie, 0, PCIE_ATU_TYPE_MEM,
-				  test->out_addr, bus_addr, PCIE_BAR4_SIZE);
+	ls_pcie_dev_iatu_outbound_set(ep, 0, PCIE_ATU_TYPE_MEM,
+				      test->out_addr, bus_addr, ep->bar4_size);
 	/* outbound iATU for MSI */
-	ls_pcie_iatu_outbound_set(pcie, 1, PCIE_ATU_TYPE_MEM,
-				  test->msi_addr, test->msi_msg_addr,
-				  PCIE_MSI_OB_SIZE);
+	ls_pcie_dev_iatu_outbound_set(ep, 1, PCIE_ATU_TYPE_MEM,
+				      test->msi_addr, test->msi_msg_addr,
+				      PCIE_MSI_OB_SIZE);
 
 	/* ATU 0 : INBOUND : map BAR0 */
-	ls_pcie_iatu_inbound_set(pcie, 0, 0, test->cfg_addr);
+	ls_pcie_dev_iatu_inbound_set(ep, 0, 0, test->cfg_addr);
 	/* ATU 2 : INBOUND : map BAR2 */
-	ls_pcie_iatu_inbound_set(pcie, 2, 2, test->cfg_addr);
+	ls_pcie_dev_iatu_inbound_set(ep, 2, 2, test->cfg_addr);
 	/* ATU 3 : INBOUND : map BAR4 */
-	ls_pcie_iatu_inbound_set(pcie, 3, 4, test->buf_addr);
+	ls_pcie_dev_iatu_inbound_set(ep, 3, 4, test->buf_addr);
+
+	/* Ensure that our EP shows the proper BAR sizes before we
+	 * enable configuration access
+	 */
+	ls_pcie_ep_dev_setup_bar(ep, 0, PCIE_BAR0_SIZE);
+	ls_pcie_ep_dev_setup_bar(ep, 1, PCIE_BAR1_SIZE);
+	ls_pcie_ep_dev_setup_bar(ep, 2, PCIE_BAR2_SIZE);
+	ls_pcie_ep_dev_setup_bar(ep, 4, ep->bar4_size);
+	ls_pcie_ep_dev_setup_bar(ep, 6, 0);
+	ls_pcie_ep_dev_cfg_enable(ep);
 
 	return 0;
 
@@ -416,8 +427,8 @@ static int ls_pcie_ep_start_test(struct ls_ep_dev *ep, char *cmd)
 	else
 		dirt = TEST_DIRT_WRITE;
 
-	if (len > PCIE_BAR4_SIZE) {
-		dev_err(&ep->dev, "max len is %d", PCIE_BAR4_SIZE);
+	if (len > ep->bar4_size) {
+		dev_err(&ep->dev, "max len is %d", ep->bar4_size);
 		return -EINVAL;
 	}
 
@@ -460,7 +471,6 @@ static ssize_t ls_pcie_ep_dbg_regs_read(struct file *filp, char __user *buffer,
 				    size_t count, loff_t *ppos)
 {
 	struct ls_ep_dev *ep = filp->private_data;
-	struct ls_pcie *pcie = ep->pcie;
 	char *buf;
 	int desc = 0, i, len;
 
@@ -468,55 +478,53 @@ static ssize_t ls_pcie_ep_dbg_regs_read(struct file *filp, char __user *buffer,
 	if (!buf)
 		return -ENOMEM;
 
-	ls_pcie_ep_dev_cfg_enable(ep);
-
 	desc += sprintf(buf + desc, "%s", "reg info:");
 	for (i = 0; i < 0x200; i += 4) {
 		if (i % 16 == 0)
 			desc += sprintf(buf + desc, "\n%08x:", i);
-		desc += sprintf(buf + desc, " %08x", readl(pcie->dbi + i));
+		desc += sprintf(buf + desc, " %08x", ls_pcie_dbi_ioread32(ep, i));
 	}
 
 	desc += sprintf(buf + desc, "\n%s", "outbound iATU info:\n");
 	for (i = 0; i < 6; i++) {
-		writel(PCIE_ATU_REGION_OUTBOUND | i,
-		       pcie->dbi + PCIE_ATU_VIEWPORT);
+		ls_pcie_dbi_iowrite32(ep, PCIE_ATU_REGION_OUTBOUND | i,
+		       PCIE_ATU_VIEWPORT);
 		desc += sprintf(buf + desc, "iATU%d", i);
 		desc += sprintf(buf + desc, "\tLOWER PHYS 0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_LOWER_BASE));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_LOWER_BASE));
 		desc += sprintf(buf + desc, "\tUPPER PHYS 0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_UPPER_BASE));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_UPPER_BASE));
 		desc += sprintf(buf + desc, "\tLOWER BUS  0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_LOWER_TARGET));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_LOWER_TARGET));
 		desc += sprintf(buf + desc, "\tUPPER BUS  0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_UPPER_TARGET));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_UPPER_TARGET));
 		desc += sprintf(buf + desc, "\tLIMIT      0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_LIMIT));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_LIMIT));
 		desc += sprintf(buf + desc, "\tCR1        0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_CR1));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_CR1));
 		desc += sprintf(buf + desc, "\tCR2        0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_CR2));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_CR2));
 	}
 
 	desc += sprintf(buf + desc, "\n%s", "inbound iATU info:\n");
 	for (i = 0; i < 6; i++) {
-		writel(PCIE_ATU_REGION_INBOUND | i,
-		       pcie->dbi + PCIE_ATU_VIEWPORT);
+		ls_pcie_dbi_iowrite32(ep, PCIE_ATU_REGION_INBOUND | i,
+		       PCIE_ATU_VIEWPORT);
 		desc += sprintf(buf + desc, "iATU%d", i);
 		desc += sprintf(buf + desc, "\tLOWER BUS  0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_LOWER_BASE));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_LOWER_BASE));
 		desc += sprintf(buf + desc, "\tUPPER BUSs 0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_UPPER_BASE));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_UPPER_BASE));
 		desc += sprintf(buf + desc, "\tLOWER PHYS 0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_LOWER_TARGET));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_LOWER_TARGET));
 		desc += sprintf(buf + desc, "\tUPPER PHYS 0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_UPPER_TARGET));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_UPPER_TARGET));
 		desc += sprintf(buf + desc, "\tLIMIT      0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_LIMIT));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_LIMIT));
 		desc += sprintf(buf + desc, "\tCR1        0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_CR1));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_CR1));
 		desc += sprintf(buf + desc, "\tCR2        0x%08x\n",
-		      readl(pcie->dbi + PCIE_ATU_CR2));
+		      ls_pcie_dbi_ioread32(ep, PCIE_ATU_CR2));
 	}
 
 	len = simple_read_from_buffer(buffer, count, ppos, buf, desc);
@@ -537,7 +545,6 @@ static ssize_t ls_pcie_ep_dbg_regs_write(struct file *filp,
 					 size_t count, loff_t *ppos)
 {
 	struct ls_ep_dev *ep = filp->private_data;
-	struct ls_pcie *pcie = ep->pcie;
 	char buf[256];
 
 	if (count >= sizeof(buf))
@@ -548,16 +555,14 @@ static ssize_t ls_pcie_ep_dbg_regs_write(struct file *filp,
 	if (copy_from_user(buf, buffer, count))
 		return -EFAULT;
 
-	ls_pcie_ep_dev_cfg_enable(ep);
-
 	if (strncmp(buf, "reg", 3) == 0) {
 		u32 reg, value;
 		int cnt;
 
 		cnt = sscanf(&buf[3], "%x %x", &reg, &value);
 		if (cnt == 2) {
-			writel(value, pcie->dbi + reg);
-			value = readl(pcie->dbi + reg);
+			ls_pcie_dbi_iowrite32(ep, value, reg);
+			value = ls_pcie_dbi_ioread32(ep, reg);
 			dev_info(&ep->dev, "reg 0x%08x: 0x%08x\n",
 				 reg, value);
 		} else {
@@ -643,12 +648,28 @@ static ssize_t ls_pcie_ep_dbg_test_write(struct file *filp,
 		}
 	} else if (strncmp(buf, "free", 4) == 0)
 		ls_pcie_ep_free_test(ep);
-	else if (strncmp(buf, "dma", 3) == 0 ||
+	else if (strncmp(buf, "memsize", 7) == 0) {
+		int i = 7;
+		u64 mem_size;
+
+		while (buf[i] == ' ')
+			i++;
+
+		if (kstrtou64(&buf[i], 0, &mem_size) || !mem_size)
+			dev_info(&ep->dev, "command: 'memsize <mem_size>', value in MiB\n");
+		else {
+			mem_size *= 1024*1024;
+			if(ls_pcie_ep_free_test(ep) == 0) {
+				ep->bar4_size = mem_size;
+			}
+		}
+	} else if (strncmp(buf, "dma", 3) == 0 ||
 		 strncmp(buf, "cpy", 3) == 0)
 		ls_pcie_ep_start_test(ep, buf);
 	else {
 		dev_info(&ep->dev, "Unknown command: %s\n", buf);
 		dev_info(&ep->dev, "Available commands:\n");
+		dev_info(&ep->dev, "\tmemsize <size_in_MB_for_BAR4_before_init>\n");
 		dev_info(&ep->dev, "\tinit <bus_addr>\n");
 		dev_info(&ep->dev, "\t<dma/cpy> <r/w> <packet_size> <loop>\n");
 		dev_info(&ep->dev, "\tfree\n");
@@ -709,8 +730,6 @@ static int ls_pcie_ep_dev_dbgfs_init(struct ls_ep_dev *ep)
 	struct ls_pcie *pcie = ep->pcie;
 	struct dentry *pfile;
 
-	ls_pcie_ep_dev_cfg_enable(ep);
-
 	ep->dir = debugfs_create_dir(dev_name(&ep->dev), pcie->dir);
 	if (!ep->dir)
 		return -ENOMEM;
diff --git a/drivers/pci/host/pci-layerscape-ep.c b/drivers/pci/host/pci-layerscape-ep.c
index 8f1cca6ee9d6..d728258114eb 100644
--- a/drivers/pci/host/pci-layerscape-ep.c
+++ b/drivers/pci/host/pci-layerscape-ep.c
@@ -27,6 +27,94 @@
 
 #include "pci-layerscape-ep.h"
 
+static void dbi_iowrite32(struct ls_ep_dev *ep, u32 value, int reg)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	void __iomem *addr = pcie->dbi + PCIE_DBI_PFa(ep->pf_idx, reg);
+
+	iowrite32(value, addr);
+}
+
+static u32 dbi_ioread32(struct ls_ep_dev *ep, int reg)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	void __iomem *addr = pcie->dbi + PCIE_DBI_PFa(ep->pf_idx, reg);
+	u32 value;
+
+	value = ioread32(addr);
+
+	return value;
+}
+
+static void dbi_iowrite16(struct ls_ep_dev *ep, u16 value, int reg)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	void __iomem *addr = pcie->dbi + PCIE_DBI_PFa(ep->pf_idx, reg);
+
+	iowrite16(value, addr);
+}
+
+static u32 dbi_ioread16(struct ls_ep_dev *ep, int reg)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	void __iomem *addr = pcie->dbi + PCIE_DBI_PFa(ep->pf_idx, reg);
+	u16 value;
+
+	value = ioread16(addr);
+
+	return value;
+}
+
+static void dbi_iowrite8(struct ls_ep_dev *ep, u8 value, int reg)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	void __iomem *addr = pcie->dbi + PCIE_DBI_PFa(ep->pf_idx, reg);
+
+	iowrite8(value, addr);
+}
+
+static u8 dbi_ioread8(struct ls_ep_dev *ep, int reg)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	void __iomem *addr = pcie->dbi + PCIE_DBI_PFa(ep->pf_idx, reg);
+	u8 value;
+
+	value = ioread8(addr);
+
+	return value;
+}
+
+static void lut_iowrite32(struct ls_ep_dev *ep, u32 value, int reg)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	void __iomem *addr = pcie->lut + PCIE_LUT_PFa(ep->pf_idx, reg);
+
+	/* Unfortunately, some chips map this differently */
+	if(pcie->drvdata->lut_bigendian) {
+		iowrite32be(value, addr);
+	}
+	else {
+		iowrite32(value, addr);
+	}
+}
+
+static u32 lut_ioread32(struct ls_ep_dev *ep, int reg)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	void __iomem *addr = pcie->lut + PCIE_LUT_PFa(ep->pf_idx, reg);
+	u32 value;
+
+	/* Unfortunately, some chips map this differently */
+	if(pcie->drvdata->lut_bigendian) {
+		value = ioread32be(addr);
+	}
+	else {
+		value = ioread32(addr);
+	}
+
+	return value;
+}
+
 struct ls_ep_dev *
 ls_pci_ep_find(struct ls_pcie *pcie, int dev_id)
 {
@@ -40,78 +128,185 @@ ls_pci_ep_find(struct ls_pcie *pcie, int dev_id)
 	return NULL;
 }
 
-static void ls_pcie_try_cfg2(struct ls_pcie *pcie, int pf, int vf)
-{
-	if (pcie->sriov)
-		writel(PCIE_LCTRL0_VAL(pf, vf),
-		       pcie->dbi + PCIE_LUT_BASE + PCIE_LUT_LCTRL0);
-}
-
 static bool ls_pcie_is_bridge(struct ls_pcie *pcie)
 {
 	u32 header_type = 0;
 
-	header_type = readl(pcie->dbi + (PCI_HEADER_TYPE & ~0x3));
+	header_type = ioread32(pcie->dbi + (PCI_HEADER_TYPE & ~0x3));
 	header_type = (header_type >> 16) & 0x7f;
 
 	return header_type == PCI_HEADER_TYPE_BRIDGE;
 }
 
-void ls_pcie_iatu_outbound_set(struct ls_pcie *pcie, int idx, int type,
-			       u64 cpu_addr, u64 pci_addr, u32 size)
+void ls_pcie_dev_set_device_and_vendor_id(struct ls_ep_dev *ep, u32 device,
+					  u32 vendor)
+{
+	u32 fullid = (device << 16) | vendor;
+
+	dbi_iowrite32(ep, PCIE_DBI_RO_WR_EN, PCIE_MISC_CONTROL_1_OFF);
+	dbi_iowrite32(ep, fullid, PCI_VENDOR_ID);
+	dbi_iowrite32(ep, 0, PCIE_MISC_CONTROL_1_OFF);
+}
+
+void ls_pcie_dev_set_class_revision(struct ls_ep_dev *ep, u32 class)
+{
+	dbi_iowrite32(ep, PCIE_DBI_RO_WR_EN, PCIE_MISC_CONTROL_1_OFF);
+	dbi_iowrite32(ep, class, PCI_CLASS_REVISION);
+	dbi_iowrite32(ep, 0, PCIE_MISC_CONTROL_1_OFF);
+}
+
+u32 ls_pcie_dev_get_class_revision(struct ls_ep_dev *ep)
+{
+	return dbi_ioread32(ep, PCI_CLASS_REVISION);
+}
+
+void ls_pcie_dbi_iowrite32(struct ls_ep_dev *ep, u32 value, int reg)
+{
+	dbi_iowrite32(ep, value, reg);
+}
+
+u32 ls_pcie_dbi_ioread32(struct ls_ep_dev *ep, int reg)
+{
+	return dbi_ioread32(ep, reg);
+}
+
+void ls_pcie_dbi_iowrite16(struct ls_ep_dev *ep, u16 value, int reg)
+{
+	dbi_iowrite16(ep, value, reg);
+}
+
+u16 ls_pcie_dbi_ioread16(struct ls_ep_dev *ep, int reg)
 {
-	writel(PCIE_ATU_REGION_OUTBOUND | idx,
-	       pcie->dbi + PCIE_ATU_VIEWPORT);
-	writel(lower_32_bits(cpu_addr),
-	       pcie->dbi +  PCIE_ATU_LOWER_BASE);
-	writel(upper_32_bits(cpu_addr),
-	       pcie->dbi + PCIE_ATU_UPPER_BASE);
-	writel(lower_32_bits(cpu_addr + size - 1),
-	       pcie->dbi + PCIE_ATU_LIMIT);
-	writel(lower_32_bits(pci_addr),
-	       pcie->dbi + PCIE_ATU_LOWER_TARGET);
-	writel(upper_32_bits(pci_addr),
-	       pcie->dbi + PCIE_ATU_UPPER_TARGET);
-	writel(type, pcie->dbi + PCIE_ATU_CR1);
-	writel(PCIE_ATU_ENABLE, pcie->dbi + PCIE_ATU_CR2);
+	return dbi_ioread16(ep, reg);
+}
+
+void ls_pcie_dbi_iowrite8(struct ls_ep_dev *ep, u8 value, int reg)
+{
+	dbi_iowrite8(ep, value, reg);
+}
+
+u8 ls_pcie_dbi_ioread8(struct ls_ep_dev *ep, int reg)
+{
+	return dbi_ioread8(ep, reg);
+}
+
+
+void ls_pcie_dev_iatu_outbound_set(struct ls_ep_dev *ep, int idx, int type,
+				   u64 cpu_addr, u64 pci_addr, u32 size)
+{
+	ep->shadow_outbound[idx].target_addr = pci_addr;
+	ep->shadow_outbound[idx].base_addr = cpu_addr;
+	ep->shadow_outbound[idx].size = size;
+	ep->shadow_outbound[idx].type = type;
+	ep->shadow_outbound[idx].region_nr = idx;
+
+	dbi_iowrite32(ep, PCIE_ATU_REGION_OUTBOUND | idx,
+	              PCIE_ATU_VIEWPORT);
+	dbi_iowrite32(ep, lower_32_bits(cpu_addr),
+	              PCIE_ATU_LOWER_BASE);
+	dbi_iowrite32(ep, upper_32_bits(cpu_addr),
+	              PCIE_ATU_UPPER_BASE);
+	dbi_iowrite32(ep, lower_32_bits(cpu_addr + size - 1),
+	              PCIE_ATU_LIMIT);
+	dbi_iowrite32(ep, lower_32_bits(pci_addr),
+	              PCIE_ATU_LOWER_TARGET);
+	dbi_iowrite32(ep, upper_32_bits(pci_addr),
+	              PCIE_ATU_UPPER_TARGET);
+	dbi_iowrite32(ep, type, PCIE_ATU_CR1);
+	dbi_iowrite32(ep, PCIE_ATU_ENABLE, PCIE_ATU_CR2);
 }
 
 /* Use bar match mode and MEM type as default */
-void ls_pcie_iatu_inbound_set(struct ls_pcie *pcie, int idx,
+void ls_pcie_dev_iatu_inbound_set(struct ls_ep_dev *ep, int idx,
 				     int bar, u64 phys)
 {
-	writel(PCIE_ATU_REGION_INBOUND | idx, pcie->dbi + PCIE_ATU_VIEWPORT);
-	writel((u32)phys, pcie->dbi + PCIE_ATU_LOWER_TARGET);
-	writel(phys >> 32, pcie->dbi + PCIE_ATU_UPPER_TARGET);
-	writel(PCIE_ATU_TYPE_MEM, pcie->dbi + PCIE_ATU_CR1);
-	writel(PCIE_ATU_ENABLE | PCIE_ATU_BAR_MODE_ENABLE |
-	       PCIE_ATU_BAR_NUM(bar), pcie->dbi + PCIE_ATU_CR2);
+	ep->shadow_inbound[idx].target_addr = phys;
+	ep->shadow_inbound[idx].bar = bar;
+	ep->shadow_inbound[idx].region_nr = idx;
+
+	dbi_iowrite32(ep, PCIE_ATU_REGION_INBOUND | idx, PCIE_ATU_VIEWPORT);
+	dbi_iowrite32(ep, (u32)phys, PCIE_ATU_LOWER_TARGET);
+	dbi_iowrite32(ep, phys >> 32, PCIE_ATU_UPPER_TARGET);
+	dbi_iowrite32(ep, PCIE_ATU_TYPE_MEM, PCIE_ATU_CR1);
+	dbi_iowrite32(ep, PCIE_ATU_ENABLE | PCIE_ATU_BAR_MODE_ENABLE |
+	       PCIE_ATU_BAR_NUM(bar), PCIE_ATU_CR2);
+}
+
+static int ls_pcie_ep_all_cfg_ready(struct ls_ep_dev *ep)
+{
+	struct ls_pcie *pcie = ep->pcie;
+	struct ls_ep_dev *epnode;
+	int cfg_ready = 1;
+
+	list_for_each_entry(epnode, &pcie->ep_list, node) {
+		if (!epnode->vf_idx)
+			cfg_ready = cfg_ready && epnode->cfg_ready;
+	}
+
+	return cfg_ready;
 }
 
 void ls_pcie_ep_dev_cfg_enable(struct ls_ep_dev *ep)
 {
-	ls_pcie_try_cfg2(ep->pcie, ep->pf_idx, ep->vf_idx);
+	if (ep->vf_idx) {
+		dev_err(ep->pcie->dev, "CFG_READY enable tried on VF%d for PCIe PF%d\n", ep->vf_idx, ep->pf_idx);
+		return;
+	}
+
+	ep->cfg_ready = 1;
+
+	/* While this is a register per PF, it turns out that the bit
+	 * is global to all PFa. So all PFa need to be set up properly
+	 * before this bit is set. It appears there is no way to
+	 * individually enable configuration for just one PF.
+	 */
+	if (ls_pcie_ep_all_cfg_ready(ep))
+		lut_iowrite32(ep, PCIE_PFa_CONFIG_CFG_READY, PCIE_PF0_CONFIG);
 }
 
-void ls_pcie_ep_setup_bar(void *bar_base, int bar, u32 size)
+void ls_pcie_ep_dev_cfg_disable(struct ls_ep_dev *ep)
 {
-	if (size < 4 * 1024)
+	if (ep->vf_idx) {
+		dev_err(ep->pcie->dev, "CFG_READY disable tried on VF%d for PCIe PF%d\n", ep->vf_idx, ep->pf_idx);
 		return;
+	}
 
+	/* It is only safe to disable the configuration if all PFs
+	 * may be disabled at the same time!
+	 */
+	ep->cfg_ready = 0;
+
+	/* While this is a register per PF, it turns out that the bit
+	 * is global to all PFa. So all PFa need to be set up properly
+	 * before this bit is set. It appears there is no way to
+	 * individually enable configuration for just one PF.
+	 */
+	lut_iowrite32(ep, 0, PCIE_PF0_CONFIG);
+}
+
+static void ls_pcie_ep_setup_bar(struct ls_ep_dev *ep, int bar, u32 size)
+{
+	dev_info(ep->pcie->dev, "Configuring PF%d BAR%d to size %08x\n",
+	         ep->dev_id, bar, size);
+
+	/* Mapping of two 32b and two 64b BARs is hardcoded into the SoC */
 	switch (bar) {
 	case 0:
-		writel(size - 1, bar_base + PCI_BASE_ADDRESS_0);
+		dbi_iowrite32(ep, size - 1, PCI_BASE_ADDRESS_0 + PCIE_BAR_MASK_OFFSET);
 		break;
 	case 1:
-		writel(size - 1, bar_base + PCI_BASE_ADDRESS_1);
+		dbi_iowrite32(ep, size - 1, PCI_BASE_ADDRESS_1 + PCIE_BAR_MASK_OFFSET);
 		break;
 	case 2:
-		writel(size - 1, bar_base + PCI_BASE_ADDRESS_2);
-		writel(0, bar_base + PCI_BASE_ADDRESS_3);
+		dbi_iowrite32(ep, size - 1, PCI_BASE_ADDRESS_2 + PCIE_BAR_MASK_OFFSET);
+		dbi_iowrite32(ep, 0, PCI_BASE_ADDRESS_3 + PCIE_BAR_MASK_OFFSET);
 		break;
 	case 4:
-		writel(size - 1, bar_base + PCI_BASE_ADDRESS_4);
-		writel(0, bar_base + PCI_BASE_ADDRESS_5);
+		dbi_iowrite32(ep, size - 1, PCI_BASE_ADDRESS_4 + PCIE_BAR_MASK_OFFSET);
+		dbi_iowrite32(ep, 0, PCI_BASE_ADDRESS_5 + PCIE_BAR_MASK_OFFSET);
+		break;
+	case 6: /* We treat the ROM address a sixth BAR intentionally */
+		dbi_iowrite32(ep, size - 1, PCI_ROM_ADDRESS + PCIE_BAR_MASK_OFFSET);
 		break;
 	default:
 		break;
@@ -120,24 +315,132 @@ void ls_pcie_ep_setup_bar(void *bar_base, int bar, u32 size)
 
 void ls_pcie_ep_dev_setup_bar(struct ls_ep_dev *ep, int bar, u32 size)
 {
-	struct ls_pcie *pcie = ep->pcie;
-	void *bar_base;
+	/* We fix up the shadow copy first so that the interrupt has
+	 * a chance to recover
+	 */
+	ep->shadow_bar[bar].size = size;
+	ep->shadow_bar[bar].bar_nr = bar;
+	ls_pcie_ep_setup_bar(ep, bar, size);
+}
 
-	if (size < 4 * 1024)
-		return;
+static void restore_bar(struct ls_ep_dev *ep)
+{
+	int i;
 
-	if (pcie->sriov)
-		bar_base = pcie->dbi;
-	else
-		bar_base = pcie->dbi + PCIE_NO_SRIOV_BAR_BASE;
+	for (i = 0; i < sizeof(ep->shadow_bar) / sizeof(ep->shadow_bar[0]); i++) {
+		struct ls_pcie_bar *bar = &ep->shadow_bar[i];
 
-	ls_pcie_ep_dev_cfg_enable(ep);
-	ls_pcie_ep_setup_bar(bar_base, bar, size);
+		if(bar->bar_nr < 0)
+			continue;
+
+		ls_pcie_ep_setup_bar(ep, bar->bar_nr, bar->size);
+	}
+}
+
+static void restore_inbound_atu(struct ls_ep_dev *ep)
+{
+	int i;
+
+	for (i = 0 ; i < sizeof(ep->shadow_inbound) / sizeof(ep->shadow_inbound[0]) ; i++) {
+		struct ls_pcie_inbound_region *region = &ep->shadow_inbound[i];
+
+		if (region->region_nr < 0)
+			continue;
+
+		ls_pcie_dev_iatu_inbound_set(ep, region->region_nr,
+					     region->bar,
+					     region->target_addr);
+	}
+}
+
+static void restore_outbound_atu(struct ls_ep_dev *ep)
+{
+	int i;
+
+	for (i = 0 ; i < sizeof(ep->shadow_outbound) / sizeof(ep->shadow_outbound[0]) ; i++) {
+		struct ls_pcie_outbound_region *region = &ep->shadow_outbound[i];
+
+		if (region->region_nr < 0)
+			continue;
+
+		ls_pcie_dev_iatu_outbound_set(ep, region->region_nr,
+					      region->type,
+					      region->base_addr,
+					      region->target_addr,
+					      region->size);
+	}
+}
+
+static irqreturn_t ls_pcie_ep_error_irq_handler(int irq, void *arg)
+{
+	struct ls_pcie *pcie = arg;
+	struct ls_ep_dev *ep0, *ep;
+	u32 intstatus;
+
+	ep0 = ls_pci_ep_find(pcie, 0);
+	if (!ep0)
+		return 0;
+
+	/* These bits are global to all PFa, so we look in PF0 */
+	intstatus = lut_ioread32(ep0, PCIE_PF0_PME_MES_DR) &
+		    lut_ioread32(ep0, PCIE_PF0_PME_MES_IER);
+
+	/* We intend to handle all int bits, so we acknowledge them
+	 * first to ensure that we are not missing any that pop up
+	 * while we are handling the current set.
+	 */
+	lut_iowrite32(ep0, intstatus, PCIE_PF0_PME_MES_DR);
+
+	if (intstatus & PCIE_PFa_PME_MES_DR_LDD)
+		dev_info(pcie->dev, "LDD (Link Down Detect)\n");
+	if (intstatus & PCIE_PFa_PME_MES_DR_HRD)
+		dev_info(pcie->dev, "HRD (Hot Reset Detect)\n");
+
+	/* Now we walk the physical functions to update all of them */
+	list_for_each_entry(ep, &pcie->ep_list, node) {
+		if (ep->vf_idx)
+			continue;
+
+		if (intstatus & PCIE_PFa_PME_MES_DR_LDD) {
+			/* Erratum A-009410 */
+			restore_bar(ep);
+			restore_inbound_atu(ep);
+			restore_outbound_atu(ep);
+			
+			/* Some chips can lose their EP CFG_READY in this
+			 * scenario. Layerscape chips keep it, so we do
+			 * not need to reenable.
+			 */
+			/* ls_pcie_ep_dev_cfg_enable(ep); */
+		}
+
+		if (intstatus & PCIE_PFa_PME_MES_DR_HRD) {
+			/* Erratum A-009410 */
+			restore_bar(ep);
+			restore_inbound_atu(ep);
+			restore_outbound_atu(ep);
+			
+			/* Some chips can lose their EP CFG_READY in this
+			 * scenario. Layerscape chips keep it, so we do
+			 * not need to reenable.
+			 */
+			/* ls_pcie_ep_dev_cfg_enable(ep); */
+		}
+	}
+
+	intstatus &= ~(PCIE_PFa_PME_MES_DR_LDD | PCIE_PFa_PME_MES_DR_HRD);
+	if (intstatus) {
+		/* Paranoia. Should not happen. If it does, we need to know */
+		dev_err(pcie->dev, "Unhandled PCIe EP error interrupt bit mask 0x%08x\n", intstatus);
+	}
+
+	return IRQ_HANDLED;
 }
 
 static int ls_pcie_ep_dev_init(struct ls_pcie *pcie, int pf_idx, int vf_idx)
 {
 	struct ls_ep_dev *ep;
+	int i;
 
 	ep = devm_kzalloc(pcie->dev, sizeof(*ep), GFP_KERNEL);
 	if (!ep)
@@ -159,6 +462,13 @@ static int ls_pcie_ep_dev_init(struct ls_pcie *pcie, int pf_idx, int vf_idx)
 		dev_set_name(&ep->dev, "pf%d",
 			     ep->pf_idx);
 
+	for (i = 0 ; i < sizeof(ep->shadow_bar) / sizeof(ep->shadow_bar[0]) ; i++)
+		ep->shadow_bar[i].bar_nr = -1;
+	for (i = 0 ; i < sizeof(ep->shadow_inbound) / sizeof(ep->shadow_inbound[0]) ; i++)
+		ep->shadow_inbound[i].region_nr = -1;
+	for (i = 0 ; i < sizeof(ep->shadow_outbound) / sizeof(ep->shadow_outbound[0]) ; i++)
+		ep->shadow_outbound[i].region_nr = -1;
+
 	list_add_tail(&ep->node, &pcie->ep_list);
 
 	return 0;
@@ -166,10 +476,11 @@ static int ls_pcie_ep_dev_init(struct ls_pcie *pcie, int pf_idx, int vf_idx)
 
 static int ls_pcie_ep_init(struct ls_pcie *pcie)
 {
+	struct ls_ep_dev *ep;
 	u32 sriov_header;
 	int pf, vf, i, j;
 
-	sriov_header = readl(pcie->dbi + PCIE_SRIOV_POS);
+	sriov_header = ioread32(pcie->dbi + PCIE_SRIOV_POS);
 
 	if (PCI_EXT_CAP_ID(sriov_header) == PCI_EXT_CAP_ID_SRIOV) {
 		pcie->sriov = PCIE_SRIOV_POS;
@@ -186,33 +497,35 @@ static int ls_pcie_ep_init(struct ls_pcie *pcie)
 			ls_pcie_ep_dev_init(pcie, i, j);
 	}
 
+	/* We want to hear about link down or hot reset events.
+	 * This setting is global to all PFa, so we set it on PF0
+	 */
+	ep = ls_pci_ep_find(pcie, 0);
+	if (ep)
+		lut_iowrite32(ep, PCIE_PFa_PME_MES_DR_LDD | PCIE_PFa_PME_MES_DR_HRD,
+			      PCIE_PF0_PME_MES_IER);
+
 	return 0;
 }
 
-static struct ls_pcie_ep_drvdata ls1043_drvdata = {
-	.lut_offset = 0x10000,
-	.ltssm_shift = 24,
-	.lut_dbg = 0x7fc,
-};
-
 static struct ls_pcie_ep_drvdata ls1046_drvdata = {
 	.lut_offset = 0x80000,
-	.ltssm_shift = 24,
+	.lut_bigendian = 1,
 	.lut_dbg = 0x407fc,
 };
 
-static struct ls_pcie_ep_drvdata ls2080_drvdata = {
+static struct ls_pcie_ep_drvdata ls2088_drvdata = {
 	.lut_offset = 0x80000,
-	.ltssm_shift = 0,
-	.lut_dbg = 0x7fc,
+	.lut_bigendian = 0,
+	.lut_dbg = 0x407fc,
 };
 
 static const struct of_device_id ls_pcie_ep_of_match[] = {
-	{ .compatible = "fsl,ls1021a-pcie", },
-	{ .compatible = "fsl,ls1043a-pcie", .data = &ls1043_drvdata },
+	/* NB: LS1021A, LS1043A families do not support EP mode! */
+	{ .compatible = "fsl,ls1012a-pcie", .data = &ls1046_drvdata },
 	{ .compatible = "fsl,ls1046a-pcie", .data = &ls1046_drvdata },
-	{ .compatible = "fsl,ls2080a-pcie", .data = &ls2080_drvdata },
-	{ .compatible = "fsl,ls2085a-pcie", .data = &ls2080_drvdata },
+	{ .compatible = "fsl,ls1088a-pcie", .data = &ls2088_drvdata },
+	{ .compatible = "fsl,ls2088a-pcie", .data = &ls2088_drvdata },
 	{ },
 };
 MODULE_DEVICE_TABLE(of, ls_pcie_ep_of_match);
@@ -258,6 +571,20 @@ static int ls_pcie_ep_probe(struct platform_device *pdev)
 		return -ENODEV;
 	}
 
+	/* Get the management/error interrupt) */
+	pcie->error_irq = irq_of_parse_and_map(pdev->dev.of_node, 0);
+	if (!pcie->error_irq) {
+		dev_err(pcie->dev, "cannot get platform resources for error irq\n");
+		return -ENOENT;
+	}
+	ret = devm_request_irq(&pdev->dev, pcie->error_irq,
+		ls_pcie_ep_error_irq_handler,
+		IRQF_SHARED, "PCIe EP error handler", pcie);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to request error irq\n");
+		return -ENODEV;
+	}
+  
 	ret = ls_pcie_ep_init(pcie);
 	if (ret)
 		return ret;
diff --git a/drivers/pci/host/pci-layerscape-ep.h b/drivers/pci/host/pci-layerscape-ep.h
index 990c0ff58b0a..cfca7140e7b4 100644
--- a/drivers/pci/host/pci-layerscape-ep.h
+++ b/drivers/pci/host/pci-layerscape-ep.h
@@ -42,33 +42,60 @@
 #define PCIE_ATU_UPPER_TARGET		0x91C
 
 /* PEX internal configuration registers */
-#define PCIE_DBI_RO_WR_EN	0x8bc /* DBI Read-Only Write Enable Register */
+#define PCIE_MISC_CONTROL_1_OFF		0x8bc /* DBI Read-Only Write Enable Register */
+#define PCIE_DBI_RO_WR_EN		(0x1 << 0) /* DBI Read-Only Write Enable Bit */
 
 /* PEX LUT registers */
-#define PCIE_LUT_BASE		0x80000
-#define PCIE_LUT_DBG		0x7FC /* PEX LUT Debug register */
-
-#define PCIE_LUT_LCTRL0		0x7F8
+#define PCIE_LUT_PFa(pf, reg)		((reg) + (pf) * 0x10000)
+#define PCIE_PF0_CONFIG			0x40014
+#define PCIE_PFa_CONFIG_CFG_READY	(0x1 << 0)
+#define PCIE_PF0_PME_MES_DR		0x40020
+#define PCIE_PFa_PME_MES_DR_PTO		(0x1 << 15)
+#define PCIE_PFa_PME_MES_DR_ENL23	(0x1 << 13)
+#define PCIE_PFa_PME_MES_DR_EXL23	(0x1 << 12)
+#define PCIE_PFa_PME_MES_DR_HRD		(0x1 << 10)
+#define PCIE_PFa_PME_MES_DR_LDD		(0x1 << 9)
+#define PCIE_PFa_PME_MES_DR_LUD		(0x1 << 7)
+#define PCIE_PF0_PME_MES_IER		0x40028
 
 #define PCIE_ATU_BAR_NUM(bar)	((bar) << 8)
-#define PCIE_LCTRL0_CFG2_ENABLE	(1 << 31)
-#define PCIE_LCTRL0_VF(vf)	((vf) << 22)
-#define PCIE_LCTRL0_PF(pf)	((pf) << 16)
-#define PCIE_LCTRL0_VF_ACTIVE	(1 << 21)
-#define PCIE_LCTRL0_VAL(pf, vf)	(PCIE_LCTRL0_PF(pf) |			   \
-				 PCIE_LCTRL0_VF(vf) |			   \
-				 ((vf) == 0 ? 0 : PCIE_LCTRL0_VF_ACTIVE) | \
-				 PCIE_LCTRL0_CFG2_ENABLE)
 
-#define PCIE_NO_SRIOV_BAR_BASE	0x1000
+
+#define PCIE_BAR_MASK_OFFSET	0x1000
 
 #define PCIE_SRIOV_POS		0x178
 #define PCIE_PF_NUM		2
 #define PCIE_VF_NUM		64
 
+/* FIX! The following are SoC and SR-IOV specific.
+ * These are the lowest common denominator mostly.
+ */
+#define PCIE_DBI_PFa(pf, reg)		((reg) + (pf) * 0x20000)
+#define PCIE_BAR_COUNT		7	/* In 32 bit terms incl. ROM! */
+#define PCIE_IATU_INBOUND_NUM	6
+#define PCIE_IATU_OUTBOUND_NUM	6
+
+struct ls_pcie_bar {
+	u32 size;
+	u32 addr;	/* Not used on EP */
+	int bar_nr;
+};
+struct ls_pcie_inbound_region {
+	u64 target_addr;
+	u32 bar;
+	int region_nr;
+};
+struct ls_pcie_outbound_region {
+	u64 target_addr;
+	u64 base_addr;
+	u32 size;
+	u32 type;
+	int region_nr;
+};
+
 struct ls_pcie_ep_drvdata {
 	u32 lut_offset;
-	u32 ltssm_shift;
+	u32 lut_bigendian;
 	u32 lut_dbg;
 };
 
@@ -82,6 +109,7 @@ struct ls_pcie {
 	phys_addr_t		out_base;
 	int			sriov;
 	int			index;
+	int			error_irq;
 };
 
 struct ls_ep_dev {
@@ -93,21 +121,44 @@ struct ls_ep_dev {
 	int			vf_idx;
 	int			dev_id;
 	void			*driver_data;
+	int			cfg_ready;
+
+	/* To support the debugfs functionality, we allow bar sizing */
+	int			bar4_size;
+
+	/* We need shadow copies of BAR and ATU information to
+	 * recover in case of a link down or hot reset event
+	 */
+	struct ls_pcie_bar 		shadow_bar[PCIE_BAR_COUNT];
+	struct ls_pcie_inbound_region	shadow_inbound[PCIE_IATU_INBOUND_NUM];
+	struct ls_pcie_outbound_region	shadow_outbound[PCIE_IATU_OUTBOUND_NUM];
 };
 
 struct ls_ep_dev *ls_pci_ep_find(struct ls_pcie *pcie, int dev_id);
 
-void ls_pcie_iatu_outbound_set(struct ls_pcie *pcie, int idx, int type,
+void ls_pcie_dev_iatu_outbound_set(struct ls_ep_dev *ep, int idx, int type,
 			      u64 cpu_addr, u64 pci_addr, u32 size);
 
 /* Use bar match mode and MEM type as default */
-void ls_pcie_iatu_inbound_set(struct ls_pcie *pcie, int idx,
+void ls_pcie_dev_iatu_inbound_set(struct ls_ep_dev *ep, int idx,
 				     int bar, u64 phys);
 
+/* Accessor functions for low level features that obey the PF assignment */
+void ls_pcie_dev_set_device_and_vendor_id(struct ls_ep_dev *ep, u32 device,
+					  u32 vendor);
+void ls_pcie_dev_set_class_revision(struct ls_ep_dev *ep, u32 class);
+u32 ls_pcie_dev_get_class_revision(struct ls_ep_dev *ep);
+void ls_pcie_dbi_iowrite32(struct ls_ep_dev *ep, u32 value, int reg);
+u32 ls_pcie_dbi_ioread32(struct ls_ep_dev *ep, int reg);
+void ls_pcie_dbi_iowrite16(struct ls_ep_dev *ep, u16 value, int reg);
+u16 ls_pcie_dbi_ioread16(struct ls_ep_dev *ep, int reg);
+void ls_pcie_dbi_iowrite8(struct ls_ep_dev *ep, u8 value, int reg);
+u8 ls_pcie_dbi_ioread8(struct ls_ep_dev *ep, int reg);
 void ls_pcie_ep_dev_setup_bar(struct ls_ep_dev *ep, int bar, u32 size);
 
 
 void ls_pcie_ep_dev_cfg_enable(struct ls_ep_dev *ep);
+void ls_pcie_ep_dev_cfg_disable(struct ls_ep_dev *ep);
 
 int ls_pcie_ep_dbgfs_init(struct ls_pcie *pcie);
 int ls_pcie_ep_dbgfs_remove(struct ls_pcie *pcie);
-- 
2.12.2

